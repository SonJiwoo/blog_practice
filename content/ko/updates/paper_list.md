---
date: "2022-10-05T00:08:29+09:00"
description: null
draft: false
title: 논문 리스트
weight: 1
---

## 1. Imbalanced Data

### 1-1. Done
|  Title  |  Year  |  Arthor  |  Journal  |    ETC.   |
| :-----: | :----: | :------: | :-------: | :-------: |
| Geometric SMOTE a geometrically enhanced drop-in replacement for SMOTE | 2019 | Douzas, G., & Bacao, F. | Information Sciences | [참고](https://towardsdatascience.com/handling-imbalanced-data-using-geometric-smote-770b49d5c7b5)  |
| Smote for regession | 2013 | Torgo, L., Ribeiro, R. P., Pfahringer, B., & Branco, P. | Progress in Artificial Intelligence. | 
| Delving into deep imbalanced regression | 2021 | Yang, Y., Zha, K., Chen, Y., Wang, H., & Katabi, D. | PMLR | ICML |
| A random forests quantile classifier for class imbalanced data | 2019 | O’Brien, R., & Ishwaran, H. | Pattern recognition | |
| Bayesian Imbalanced Regression Debiasing | 2021 | Ren, J., Zhang, M., Yu, C., & Liu, Z. | | |

{{< expand "APA version" >}}
1. Douzas, G., & Bacao, F. (2019). Geometric SMOTE a geometrically enhanced drop-in replacement for SMOTE. Information Sciences, 501, 118-135.
1. Torgo, L., Ribeiro, R.P., Pfahringer, B., Branco, P. (2013). SMOTE for Regression. In: Correia, L., Reis, L.P., Cascalho, J. (eds) Progress in Artificial Intelligence. EPIA 2013. Lecture Notes in Computer Science(), vol 8154. Springer, Berlin, Heidelberg.
1. Yang, Y., Zha, K., Chen, Y., Wang, H., & Katabi, D. (2021, July). Delving into deep imbalanced regression. In International Conference on Machine Learning (pp. 11842-11851). PMLR.
1. O’Brien, R., & Ishwaran, H. (2019). A random forests quantile classifier for class imbalanced data. Pattern recognition, 90, 232-249.
1. Ren, J., Zhang, M., Yu, C., & Liu, Z. (2021). Bayesian Imbalanced Regression Debiasing.
{{< /expand >}}

### 1-2. To Read
1. Camacho, L., Douzas, G., & Bacao, F. (2022). Geometric SMOTE for regression. Expert Systems with Applications, 116387.
1. Chen, B., Xia, S., Chen, Z., Wang, B., & Wang, G. (2021). RSMOTE: A self-adaptive robust SMOTE for imbalanced problems with label noise. Information Sciences, 553, 397-428.
1. Kamycki, K., Kapuscinski, T., & Oszust, M. (2019). Data augmentation with suboptimal warping for time-series classification. Sensors, 20(1), 98.
1. Dablain, D., Krawczyk, B., & Chawla, N. V. (2022). DeepSMOTE: Fusing deep learning and SMOTE for imbalanced data. IEEE Transactions on Neural Networks and Learning Systems.
1. Torgo, L., & Ribeiro, R. (2007, September). Utility-based regression. In European conference on principles of data mining and knowledge discovery (pp. 597-604). Springer, Berlin, Heidelberg.
1. Branco, P., Torgo, L., & Ribeiro, R. P. (2017, October). SMOGN: a pre-processing approach for imbalanced regression. In First international workshop on learning with imbalanced domains: Theory and applications (pp. 36-50). PMLR.
1. Branco, P., Torgo, L., & Ribeiro, R. P. (2019). Pre-processing approaches for imbalanced distributions in regression. Neurocomputing, 343, 76-99.
1. Xia, S., Zheng, Y., Wang, G., He, P., Li, H., & Chen, Z. (2021). Random space division sampling for label-noisy classification or imbalanced classification. IEEE Transactions on Cybernetics.

## 2. Anomaly Detection
