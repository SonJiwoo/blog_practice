---
collapsible: false
date: "2021-03-11T10:08:56+09:00"
description: Entropy, Cross-Entropy, KL-Divergence
title: Entropy, KL-Divergence
weight: 2
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="entropy" class="section level2">
<h2>Entropy</h2>
<p>정보량 = 불확실성
<span class="math display">\[H(p) = -\sum_{i=1}p_i log(p_i)\]</span></p>
</div>
<div id="cross-entropy" class="section level2">
<h2>Cross-Entropy</h2>
<p>p에 대해, 전략 Q를 사용했을 때의 불확실성
<span class="math display">\[H(p,q) = -\sum_{i=1}p_i log(q_i)\]</span></p>
</div>
<div id="kl-divergence" class="section level2">
<h2>KL-Divergence</h2>
<p><span class="math display">\[\begin{align}
KL(p||q) &amp;= \sum_{i=1}p_i log\frac{p_i}{q_i} \\
&amp;= H(p,q) - H(p)
\end{align}\]</span></p>
</div>
